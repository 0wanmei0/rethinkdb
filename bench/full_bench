#!/bin/bash

RETHINKDB_BRANCH="master"

# Set up the directory
BENCH_DIR="$HOME/bench/$(date +%Y-%m-%d-%H:%M)"
mkdir -p "$BENCH_DIR"
rm -f $HOME/bench/latest
ln -s $BENCH_DIR $HOME/bench/latest
#exec > "$BENCH_DIR/full_bench.log" 2>&1


# Horrible but working way of finding the argument after --email.
# TODO
email="$(perl -e 'use List::Util qw(first); my $email_idx = 1 + first { $ARGV[$_] eq "--email" } 0 .. $#ARGV; print $ARGV[$email_idx]' -- "$@")"

# Build the server and the stress client
cd src
git checkout $RETHINKDB_BRANCH
make clean
make -j DEBUG=0 VALGRIND=0 FAST_PERFMON=1
git checkout master
cd ../bench/stress-client
make clean stress libstress.so LIBMEMCACHED=0
scp stress puzzler:/home/teapot/stress
scp libstress.so puzzler:/home/teapot/libstress.so
scp stress.py puzzler:/home/teapot/stress.py
# This is a hack. The rgetMix workload needs to run its own Python script remotely because
# its workload cannot be expressed as a stress-client command line. We manually copy the
# custom stress client to puzzler.
scp ../workloads/rgetMix/rgetMixStressClient.py puzzler:/home/teapot/rgetMixStressClient.py
STRESS_CLIENT="puzzler:/home/teapot/stress"
# Hack to tell the rgetMix workload where its custom stress client has been put
export RGET_MIX_STRESS_CLIENT="puzzler:/home/teapot/rgetMixStressClient.py"
cd ../dbench

# Some helper functions
function delete_database_files() { # They are large and useless.
    rm -f "$(find "$BENCH_DIR" -name rethinkdb_data)"
}

# Set the I/O scheduler to noop
for DRIVE in sdf sdg sdh sdi; do
    sudo set-scheduler $DRIVE noop
done

# Set up the SSDs as individual devices, and note their names to pass to rethinkdb.
#SSD_DRIVES="$(sudo /usr/local/bin/raidconfig ssd single | sed 's/^/-f /; s/$/ /' | tr -d '\n')"
SSD_DRIVES="-f /dev/sdf -f /dev/sdg -f /dev/sdh -f /dev/sdi"
HDD_DRIVES="-f /dev/sdb -f /dev/sdc -f /dev/sdd -f /dev/sde"

SERVER_HOSTS="magneto,magneto2"
CANONICAL_CLIENTS="512"
CANONICAL_DURATION="1800s"
CANONICAL_MULTIRUN_DURATION="300s"

DATABASE="rethinkdb"

# Run workloads
for WORKLOAD in ../workloads/*; do
    if [ -d "$WORKLOAD" ]; then
        echo -e "\n\E[37;44m\033[1m<----- Running workload in $WORKLOAD ----->\033[0m\n"
        export BENCH_DIR
        export SSD_DRIVES
        export HDD_DRIVES
        export DATABASE
        export SERVER_HOSTS
        export CANONICAL_CLIENTS
        export CANONICAL_DURATION
        export CANONICAL_MULTIRUN_DURATION
        export STRESS_CLIENT
    
        if [ -e "$WORKLOAD/Setup" ]; then
            "$WORKLOAD/Setup"
        fi
        
        for CONFIGURATION in $( find "$WORKLOAD" -maxdepth 1 -type f -name "R*" | sort ); do
            echo -e "\n\033[1mRunning $CONFIGURATION\033[0m"
            if [ -e "$BENCH_DIR/environment" ]; then
                . "$BENCH_DIR/environment"
            fi
            $CONFIGURATION
        done
        
        if [ -e "$WORKLOAD/Teardown" ]; then
            if [ -e "$BENCH_DIR/environment" ]; then
                . "$BENCH_DIR/environment"
            fi
            "$WORKLOAD/Teardown"
        fi
        
        if [ -e "$BENCH_DIR/environment" ]; then
            rm -f "$BENCH_DIR/environment"
        fi
    fi
done

# TODO:
# Out of RAM performance
# Canonical workload on HDD performance


# Now that all benchmarks are done, delete any database files that might have been left over
delete_database_files

# OProfile example
#./dbench -d  "$BENCH_DIR/prof_output"     -H magneto,magneto2 {server}rethinkdb:'-c 12 -s 128' {client}stress[puzzler:/home/teapot/stress]:'-c 512 -d 10000000'             iostat:1 vmstat:1 rdbstat:1 oprofile
#delete_database_files

# Generate statistics and email.
cd ../format
./report.py "$BENCH_DIR" "$email" > "$BENCH_DIR/report.log" 2>&1

