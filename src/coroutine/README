Notes about coroutines in RethinkDB
Daniel Ehrenberg

Coroutines should help make the RethinkDB source code easier to write and modify, allowing us to use more advanced algorithms and eliminate bugs.

The coroutine library is based on libcoroutine, by Steve Dekorte and others. It was retrieved from https://github.com/stevedekorte/coroutine and appears not to be in active development. libcoroutine is ported to many platforms, some of which will never be relevant to RethinkDB. I stripped the code down to just the POSIX part based on ucontext and a possibly-working Windows fibers implementation. The remnants are in Coro.{cc,hpp}. This doesn't really bare much resemblance to the original, as there are significant API changes as well. To make things faster, I switched out swapcontext in favor of an optimized version called lightweight_swapcontext, in asm.S, based on the glibc implementation of swapcontext. In addition, coroutines are never deleted, but rather put in a free list when their function is not in use anymore, so that allocation is faster. See the blog posts for more details on the performance optimizations.

libcoroutine is wrapped by coroutines.{cc,hpp}, providing a higher-level interface. The interface provides fairly minimal concepts: we just have the ability to yield (coro_t::wait()), and the ability to schedule another coroutine to run (coro_t::notify()). Coroutines can also be moved to other CPUs (coro_t::move_to_thread(int)), and there is an RAII wrapper around this (coro_t::on_cpu_t). For easier coordination, there are condition variables (coro_t::cond_var<T>) and a type for waiting on multiple notify messages (coro_t::multi_wait_t). To launch a coroutine, use void coro_t::spawn(fn, args...) with any number of arguments (up to 6, but this could easily be extended). This is based on boost::bind, so fn can be any kind of function object, or even a member function pointer (with the first arg being the receiver). Here, the return value of fn is inaccessible. To spawn a coroutine where the return value can be accessed, use coro_t::cond_var_t<T> coro_t::task(fn, args...) for a fn returning T. Joining the condition variable will cause the joining coroutine to block until the task is complete.

The size of a coroutine stack is determined by the command line parameter --coroutine-stack-size, default 64k. The bottom page of a coroutine is mprotected so no reads or writes can be done to it without triggering a memory fault. This is intended to catch stack overflow early, as a hard error rather than letting stack overflow corrupt the state of the program as a soft error. In debug mode, a useful error message will be printed if the stack overflows, and in release mode, a segfault will occur. This will only happen if a write or read happens within the protected page, however: if a large object is allocated on the stack and the *following* page is written to, then this may result in a soft error, corrupting the state of the program.

In general, we want to discourage recursion, as this messes up the strategy of having relatively small coroutine stacks. But in the current callback-based code base, there is a lot of long recursive code paths that come up when potentially blocking calls call their callback immediately. For example, if network calls return immediately, then in both reading and writing large values to and from the socket, we may have a maximum stack size proportional to the number of blocks used. These recursive paths need to be changed by instead using iteration+coroutines (which we plan to change them to eventually anyway) if we want small stack sizes. Alternatively, we could switch to a strategy of using very large stacks and hope that only the important portion of them is committed to physical memory. Maybe these can be allocated with mmap and freed with munmap, if tcmalloc seems to cause too much overhead here. This depends on overcommitting, unless we do something like catch page faults and use mremap to grow the stack, but this could fail. Overcommitting may be disabled in some system configurations and may have some overhead in kernel datastructures. I believe that we don't actually want to promote recursion in the first place. The problematic cases that I'm aware of are all tail recursion, so they should be convertible to a while loop as soon as enough stuff uses coroutines.

Code will be converted to using coroutines gradually, as you can already see in this branch. Code using callbacks and using coroutines can coexist easily. To wrap callback-based code in a coroutine interface, make a procedure which takes the current coroutine (coro_t::self()), stores it somewhere and waits. The callback notifies that coroutine, and stores the return value in a place that the coroutine could see. To wrap coroutine-based code in a callback-based interface is even easier: just spawn a coroutine which calls the callback when it's done. Unconditionally return false if the caller needs a boolean about whether it is returning immediately.

Right now, coroutines don't have any metadata: they're basically just a stack with an instruction pointer. But they could. Two possible types of data, with concrete applications:
 - A comment in the epoll loop mentions that we may want to batch get or set requests, so we can have better CPU cache behavior. Another reason to batch these things is to batch sets in high durability mode so that each individual set does not require disk access. But right now, the epoll loop doesn't know what coroutine might be a get or set request. This could be represented in some metadata in the coroutine. The metadata could be accessed from a virtual method on cpu_message_t. It could have a default definition to report no metadata, and be overwritten by coroutines to report information that would be useful to the scheduler. This might be set at spawn-time, or it might be changed during the run of the coroutine. (RAII for dynamically scoped metadata, anyone?)
 - Coroutine stack overflow right now reports the core that the coroutine was launched on, but we could get any kind of information out of the coroutine that we might want. For example, maybe spawn/task could take an additional argument which is a string describing what the coroutine is doing. Or it could remember the name of the function that it was starting on. This could be printed out as part of the stack overflow error message. Another debugging application: we could maintain a list of waiting coroutines (in debug mode only) and the server could have an extra command to get the metadata of all waiting coroutines. This could help us to debug deadlocks.
